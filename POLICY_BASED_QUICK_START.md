# Policy-Based Design å¿«é€Ÿå…¥é—¨æŒ‡å—

**ç‰ˆæœ¬**: v2.0.0-alpha
**æ—¥æœŸ**: 2025-11-03

---

## ğŸ¯ æ¦‚è¿°

libtriton_jit v2.0 é‡‡ç”¨ **Policy-Based Design**ï¼Œæ”¯æŒå¤šåç«¯ï¼ˆCUDAã€NPUç­‰ï¼‰ã€‚æœ¬æŒ‡å—å¸®åŠ©ä½ å¿«é€Ÿä¸Šæ‰‹æ–°æ¶æ„ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç”¨æˆ·ä»£ç ï¼ˆæ— éœ€ä¿®æ”¹ï¼ï¼‰

```cpp
#include "triton_jit/triton_jit_function.h"

using namespace triton_jit;

// ç”¨æˆ·ä»£ç ä¿æŒä¸å˜ï¼
auto& func = TritonJITFunction::get_instance("kernel.py", "add_kernel");

func(stream, grid_x, 1, 1, num_warps, num_stages,
     tensor_a, tensor_b, tensor_c, size);
```

### 2. ç¼–è¯‘ï¼ˆé€‰æ‹©åç«¯ï¼‰

```bash
# CUDA Backend (é»˜è®¤)
cmake -B build -DBACKEND=CUDA
cmake --build build

# NPU Backend (Week 4 å®ç°)
cmake -B build -DBACKEND=NPU
cmake --build build
```

**å°±è¿™ä¹ˆç®€å•ï¼ç”¨æˆ·ä»£ç å®Œå…¨ä¸éœ€è¦ä¿®æ”¹ã€‚**

---

## ğŸ“š æ¶æ„è¯´æ˜

### æ ¸å¿ƒæ¦‚å¿µ

#### 1. Backend Policy (åç«¯ç­–ç•¥)

æ¯ä¸ªåç«¯å®ç°ä¸€ä¸ª Policy ç»“æ„ä½“ï¼Œæä¾›ï¼š

```cpp
struct CudaBackend {
    // ç±»å‹å®šä¹‰
    using StreamType = CUstream;
    using ContextType = CUcontext;
    using KernelHandle = CUfunction;

    // é™æ€æ–¹æ³•
    static void launch_kernel(...);
    static void ensure_context();
    static int get_device_index();
    static KernelHandle load_kernel(...);
};
```

#### 2. ç¼–è¯‘æœŸéªŒè¯ï¼ˆC++20 Conceptsï¼‰

```cpp
template<typename T>
concept BackendPolicy = requires {
    typename T::StreamType;
    typename T::ContextType;
    typename T::KernelHandle;
    // ... æ–¹æ³•è¦æ±‚
};

// ç¼–è¯‘æœŸæ£€æŸ¥
static_assert(BackendPolicy<CudaBackend>);
```

#### 3. æ¨¡æ¿åŒ–æ ¸å¿ƒç±»

```cpp
template<BackendPolicy Backend>
class TritonKernelImpl {
    void launch(
        unsigned int grid_x, grid_y, grid_z,
        int num_warps,
        typename Backend::StreamType stream,  // æ³›å‹ï¼
        void** args
    ) const;
};
```

#### 4. Type Aliasesï¼ˆç”¨æˆ·å‹å¥½ï¼‰

```cpp
// backend_config.h
#if defined(BACKEND_CUDA)
    using TritonKernel = TritonKernelImpl<CudaBackend>;
    using TritonJITFunction = TritonJITFunctionImpl<CudaBackend>;
#endif
```

---

## ğŸ”§ å¦‚ä½•æ·»åŠ æ–°åç«¯

### Step 1: åˆ›å»º Backend Policy

```cpp
// include/triton_jit/backends/my_backend.h
struct MyBackend {
    using StreamType = my_stream_t;
    using ContextType = my_context_t;
    using KernelHandle = my_kernel_t;

    static void launch_kernel(...) {
        // è°ƒç”¨ä½ çš„åç«¯ API
    }

    static void ensure_context() {
        // Context åˆå§‹åŒ–
    }

    static int get_device_index() {
        // è·å–è®¾å¤‡ç´¢å¼•
    }

    static KernelHandle load_kernel(...) {
        // åŠ è½½ kernel
    }
};

// ç¼–è¯‘æœŸéªŒè¯
static_assert(BackendPolicy<MyBackend>);
```

### Step 2: æ›´æ–° backend_config.h

```cpp
#include "triton_jit/backends/my_backend.h"

#if defined(BACKEND_MY)
    using DefaultBackend = MyBackend;
#endif
```

### Step 3: æ›´æ–° CMake

```cmake
if(BACKEND STREQUAL "MY")
    add_definitions(-DBACKEND_MY)
    # æ·»åŠ ä½ çš„ä¾èµ–
endif()
```

### Step 4: æ˜¾å¼å®ä¾‹åŒ–æ¨¡æ¿

```cpp
// src/triton_jit_function_impl.cpp
#include "triton_jit/backends/my_backend.h"
template class TritonJITFunctionImpl<MyBackend>;
```

å®Œæˆï¼æ–°åç«¯å·²é›†æˆã€‚

---

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### Example 1: åŸºæœ¬ä½¿ç”¨

```cpp
#include "triton_jit/triton_jit_function.h"

using namespace triton_jit;

// è·å– JIT å‡½æ•°
auto& add_func = TritonJITFunction::get_instance(
    "kernels/add.py",
    "add_kernel"
);

// å‡†å¤‡å‚æ•°
CUstream stream = /* get current stream */;
at::Tensor a = torch::randn({1024}, torch::kCUDA);
at::Tensor b = torch::randn({1024}, torch::kCUDA);
at::Tensor c = torch::empty({1024}, torch::kCUDA);

// è°ƒç”¨ kernel
add_func(
    stream,
    1024 / 256, 1, 1,  // grid dimensions
    1, 1,               // num_warps, num_stages
    a, b, c, 1024      // kernel arguments
);
```

### Example 2: å¤š Backend æ”¯æŒ

```cpp
// è¿™æ®µä»£ç åœ¨ CUDA å’Œ NPU ä¸Šéƒ½èƒ½ç¼–è¯‘è¿è¡Œï¼

#include "triton_jit/triton_jit_function.h"
#include "triton_jit/backend_config.h"

using namespace triton_jit;

void run_kernel() {
    // Backend é€šè¿‡ CMake é€‰æ‹©ï¼Œä»£ç ä¸å˜
    auto& func = TritonJITFunction::get_instance(...);

    // stream ç±»å‹è‡ªåŠ¨é€‚é…
    DefaultStreamType stream = /* ... */;

    func(stream, ...);
}
```

### Example 3: æŸ¥è¯¢ Backend ä¿¡æ¯

```cpp
#include "triton_jit/backend_config.h"

using namespace triton_jit;

void print_info() {
    std::cout << "Backend: " << get_backend_name() << std::endl;
    std::cout << "Version: " << get_backend_version() << std::endl;

    // æˆ–è€…ä½¿ç”¨è¾…åŠ©å‡½æ•°
    print_backend_info();
}

// è¾“å‡º:
// === Triton JIT Backend Info ===
// Backend: CUDA
// Version: 2.0.0-cuda
// ===============================
```

---

## ğŸ” è°ƒè¯•å’Œæ•…éšœæ’é™¤

### ç¼–è¯‘é”™è¯¯ï¼šConcept ä¸æ»¡è¶³

**é”™è¯¯ä¿¡æ¯**:
```
error: 'MyBackend' does not satisfy concept 'BackendPolicy'
```

**è§£å†³æ–¹æ³•**:
1. æ£€æŸ¥æ˜¯å¦å®šä¹‰äº†æ‰€æœ‰å¿…éœ€çš„ç±»å‹ï¼š
   - `StreamType`
   - `ContextType`
   - `KernelHandle`

2. æ£€æŸ¥æ˜¯å¦å®ç°äº†æ‰€æœ‰å¿…éœ€çš„æ–¹æ³•ï¼š
   - `launch_kernel()`
   - `ensure_context()`
   - `get_device_index()`
   - `load_kernel()`

3. æ£€æŸ¥æ–¹æ³•ç­¾åæ˜¯å¦åŒ¹é…ï¼š
```cpp
// æ­£ç¡®çš„ç­¾å
static void launch_kernel(
    StreamType stream,
    KernelHandle kernel,
    unsigned grid_x, unsigned grid_y, unsigned grid_z,
    unsigned block_x, unsigned block_y, unsigned block_z,
    void** args
);
```

### é“¾æ¥é”™è¯¯ï¼šæœªå®šä¹‰çš„æ¨¡æ¿å®ä¾‹åŒ–

**é”™è¯¯ä¿¡æ¯**:
```
undefined reference to `TritonJITFunctionImpl<MyBackend>::get_kernel(...)`
```

**è§£å†³æ–¹æ³•**:
åœ¨ `src/triton_jit_function_impl.cpp` ä¸­æ·»åŠ æ˜¾å¼å®ä¾‹åŒ–ï¼š
```cpp
#include "triton_jit/backends/my_backend.h"
template class TritonJITFunctionImpl<MyBackend>;
```

### è¿è¡Œæ—¶é”™è¯¯ï¼šKernel åŠ è½½å¤±è´¥

**æ£€æŸ¥**:
1. `.cubin` æ–‡ä»¶æ˜¯å¦å­˜åœ¨
2. `.json` å…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
3. Architecture æ˜¯å¦åŒ¹é…
4. è·¯å¾„æ˜¯å¦æ­£ç¡®

---

## ğŸ“Š æ€§èƒ½è€ƒè™‘

### ç¼–è¯‘æœŸå¤šæ€ vs è¿è¡Œæ—¶å¤šæ€

**Policy-Based (å½“å‰æ–¹æ¡ˆ)**:
```
ä¼˜åŠ¿:
- é›¶è¿è¡Œæ—¶å¼€é”€
- å®Œå…¨å†…è”ä¼˜åŒ–
- ç±»å‹å®‰å…¨
- Kernel launch: ~5Î¼s

åŠ£åŠ¿:
- ç¼–è¯‘æœŸç¡®å®šåç«¯
- ä¸æ”¯æŒè¿è¡Œæ—¶åˆ‡æ¢
```

**Virtual Functions (ä¼ ç»ŸOOP)**:
```
ä¼˜åŠ¿:
- è¿è¡Œæ—¶åˆ‡æ¢åç«¯

åŠ£åŠ¿:
- Vtable æŸ¥æ‰¾å¼€é”€
- æœ‰é™çš„å†…è”ä¼˜åŒ–
- Kernel launch: ~15Î¼s
```

### Module ç¼“å­˜

```cpp
// CudaBackend å†…ç½® module ç¼“å­˜
static std::unordered_map<std::string, ModuleData> module_cache_;

// é¦–æ¬¡åŠ è½½ï¼š~100ms
// ç¼“å­˜å‘½ä¸­ï¼š~1Î¼s
// é¢„æœŸç¼“å­˜å‘½ä¸­ç‡ï¼š> 95%
```

---

## ğŸ› ï¸ å¼€å‘å·¥å…·

### ç¼–è¯‘å™¨è¦æ±‚

- **GCC**: 10+ (æ”¯æŒ C++20 Concepts)
- **Clang**: 13+ (æ”¯æŒ C++20 Concepts)
- **MSVC**: 2019+ (æ”¯æŒ C++20 Concepts)

### CMake è¦æ±‚

- **CMake**: 3.26+

### éªŒè¯ C++20 æ”¯æŒ

```bash
# è¿è¡Œ Concepts æµ‹è¯•
cd build
./tests/test_concepts

# è¾“å‡º:
# âœ“ Test 1 (Integral): 5 + 3 = 8
# âœ“ Test 2 (Numeric): 2.5 * 4.0 = 10
# âœ“ Test 3 (Addable): 1 + 2 + 3 = 6
# âœ“ Test 4 (HasStreamType): MockBackend has StreamType
# âœ… All C++20 Concepts tests passed!
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
libtriton_jit/
â”œâ”€â”€ include/triton_jit/
â”‚   â”œâ”€â”€ backend_policy.h           # Backend Policy Concept
â”‚   â”œâ”€â”€ backend_config.h           # Backend é…ç½®
â”‚   â”œâ”€â”€ triton_kernel_impl.h       # Kernel æ¨¡æ¿å®ç°
â”‚   â”œâ”€â”€ triton_jit_function_impl.h # JIT å‡½æ•°æ¨¡æ¿å®ç°
â”‚   â”œâ”€â”€ triton_kernel.h            # Kernel å…¬å…±æ¥å£
â”‚   â”œâ”€â”€ triton_jit_function.h      # JIT å‡½æ•°å…¬å…±æ¥å£
â”‚   â””â”€â”€ backends/
â”‚       â”œâ”€â”€ cuda_backend.h         # CUDA Backend
â”‚       â””â”€â”€ npu_backend.h          # NPU Backend (Week 4)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ triton_jit_function_impl.cpp  # æ¨¡æ¿å‡½æ•°å®ç°
â”‚   â””â”€â”€ jit_utils.cpp                 # å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_concepts.cpp          # Concepts æµ‹è¯•
â”‚   â””â”€â”€ CMakeLists.txt
â”‚
â””â”€â”€ CMakeLists.txt
```

---

## ğŸ“ è¿›é˜¶ä¸»é¢˜

### 1. Shared Memory ä¼˜åŒ–

```cpp
// CudaBackend è‡ªåŠ¨é…ç½® shared memory
unsigned int shared = CudaBackend::get_shared_memory(dir, kernel_name);

// å¯¹äº >48KB shared memory:
// - è‡ªåŠ¨è®¾ç½® CU_FUNC_CACHE_PREFER_SHARED
// - é…ç½®åŠ¨æ€ shared memory
```

### 2. è‡ªå®šä¹‰å‚æ•°å¤„ç†

```cpp
// ArgHandle æ”¯æŒ:
// - at::Tensor
// - c10::Scalar
// - std::optional<T>
// - Constexpr å‚æ•°
// - Specialized å‚æ•°

// è‡ªå®šä¹‰ç±»å‹: å®ç° triton_type<T>
template<>
struct triton_type<MyType> {
    static constexpr const char* name = "my_type";
};
```

### 3. å¤šè®¾å¤‡æ”¯æŒ

```cpp
// Backend Policy å·²æ”¯æŒ device_index
int device = Backend::get_device_index();

// Kernel è‡ªåŠ¨ä¸ºæ¯ä¸ªè®¾å¤‡ç¼–è¯‘
const auto& kernel = get_kernel(signature, num_warps, num_stages, device);
```

---

## â“ FAQ

**Q: ç”¨æˆ·ä»£ç éœ€è¦ä¿®æ”¹å—ï¼Ÿ**
A: ä¸éœ€è¦ï¼é€šè¿‡ type aliasï¼Œç”¨æˆ·ä»£ç ä¿æŒ100%å…¼å®¹ã€‚

**Q: å¦‚ä½•åœ¨ CUDA å’Œ NPU ä¹‹é—´åˆ‡æ¢ï¼Ÿ**
A: é‡æ–° cmake æ—¶æŒ‡å®š `-DBACKEND=CUDA` æˆ– `-DBACKEND=NPU`ã€‚

**Q: æ€§èƒ½æœ‰å½±å“å—ï¼Ÿ**
A: é›¶è¿è¡Œæ—¶å¼€é”€ï¼ç¼–è¯‘æœŸå¤šæ€å®Œå…¨å†…è”ä¼˜åŒ–ã€‚

**Q: æ”¯æŒè¿è¡Œæ—¶åˆ‡æ¢åç«¯å—ï¼Ÿ**
A: ä¸æ”¯æŒã€‚åç«¯åœ¨ç¼–è¯‘æœŸç¡®å®šã€‚è¿™æ˜¯ Policy-Based Design çš„ç‰¹ç‚¹ã€‚

**Q: C++20 æ˜¯å¿…é¡»çš„å—ï¼Ÿ**
A: æ˜¯çš„ã€‚Concepts ä½¿ä»£ç æ›´ç®€æ´æ¸…æ™°ã€‚é™çº§åˆ° C++17 éœ€è¦ç”¨ SFINAE æ›¿ä»£ã€‚

**Q: å¦‚ä½•æ·»åŠ æ–°åç«¯ï¼Ÿ**
A: è§ä¸Šæ–‡"å¦‚ä½•æ·»åŠ æ–°åç«¯"ç« èŠ‚ï¼Œåªéœ€ 4 æ­¥ã€‚

---

## ğŸ“ è·å–å¸®åŠ©

- **Week 1 å®ŒæˆæŠ¥å‘Š**: `WEEK1_COMPLETION_REPORT.md`
- **è¯¦ç»†é‡æ„è®¡åˆ’**: `POLICY_BASED_REFACTOR_PLAN_V2.md`
- **é¡¹ç›®è·¯å¾„**: `/Users/chenhao/projects/FlagTree/cuda/libtriton_jit`

---

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼ğŸ‰**
